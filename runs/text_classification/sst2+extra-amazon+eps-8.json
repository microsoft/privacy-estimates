{
  "run_name": "sst2-extra_amazon-eps_8",
  "target_epsilon": 8.0,
  "num_train_epochs": 3.0,
  "learning_rate": 5e-4,
  "base_dataset": "SST2-train",
  "extra_dataset": "AmazonPolarity-train",
  "test_dataset": "SST2-validation",
  "N": 800,
  "m": 10,
  "model_name": "roberta-base",
  "gradient_accumulation_steps": 64,
  "per_device_train_batch_size": 16,
  "per_sample_max_grad_norm": 0.1,
  "max_sequence_length": 67,
  "seed": 193120,
  "num_classes": 2,
  "delta": 1e-5
}